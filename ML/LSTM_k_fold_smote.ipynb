{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"KBkxr8x_Vhax"},"source":["### LSTM\n","### k-fold cross varidation\n","### smoteで訓練データを増やす"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_JSI4y7Oxep"},"outputs":[],"source":["#ライブラリのmountという関数を使って個人のGoogle Driveを'/content/drive'にマウント\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkBxqEWXYonF"},"outputs":[],"source":["!pip install keras\n","!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5ToI-49O9Mt"},"outputs":[],"source":["# cnn model\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from numpy import mean\n","from numpy import std\n","from numpy import vstack\n","from pandas import read_csv\n","from matplotlib import pyplot\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import Activation\n","from keras.layers import Conv1D\n","from keras.layers import ConvLSTM2D\n","from keras.layers import MaxPooling1D\n","from keras.utils import to_categorical\n","from tensorflow.keras.optimizers import SGD\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.model_selection import  KFold, StratifiedKFold\n","from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","from imblearn.over_sampling import SMOTE\n","from collections import Counter\n","\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGlt38hFuTLt"},"outputs":[],"source":["# params\n","test_size = 0.2\n","epochs=30\n","batch_size=16\n","lr=0.1\n","n_splits=5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4wA2ZlfNqTjS"},"outputs":[],"source":["files = [\"filename1\", \"filename2\", \"filename3\",]\n","images = 259\n","frames = 550\n","channels = 6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12ugEhfqqXHs"},"outputs":[],"source":["def load_group(filenames, dataset, prefix=''):\n","    loaded_EEG = list()\n","    loaded_label = list()\n","    for name in filenames:\n","        with open(f'{prefix}{name}_{dataset}.dat', mode='rb') as f:\n","          data_EEG = pickle.load(f)\n","          label = pickle.load(f)\n","          data_EEG = data_EEG.tolist()\n","          label = label.tolist()\n","          loaded_EEG.append(data_EEG)\n","          loaded_label.append(label)\n","    # stack group so that features are the 3rd dimension\n","    loaded_EEG = vstack(loaded_EEG)\n","    loaded_label = np.array(loaded_label)[:, :, 1].reshape(-1, 1)\n","    loaded_EEG = np.transpose(loaded_EEG, (0,2,1))\n","\n","    return loaded_EEG, loaded_label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PsZ4w-CpqchA"},"outputs":[],"source":["def load_label(labelcategory, Y):\n","    if labelcategory == \"labelA\":\n","      # 1←好感度は高め\n","      # 2←不気味ではない\n","      # 3←HL90~100(不気味)\n","      # 4←HL100（人）\n","      Y = Y.astype(np.float16)\n","      for i in range(len(Y)):\n","        if Y[i] == 100:\n","          Y[i] = 4\n","        elif  (Y[i]<100) & (Y[i]>=90):\n","          Y[i] = 3\n","        elif  (Y[i]<90) & (Y[i]>=80):\n","            Y[i] = 2\n","        elif  (Y[i]<80) & (Y[i]>=70):\n","          Y[i] = 2\n","        elif  (Y[i]<70) & (Y[i]>=60):\n","            Y[i] = 2\n","        elif  (Y[i]<60) & (Y[i]>=50):\n","          Y[i] = 1\n","        elif  (Y[i]<50) & (Y[i]>=40):\n","            Y[i] = 1\n","        elif  (Y[i]<40) & (Y[i]>=30):\n","          Y[i] = 1\n","        elif  (Y[i]<30) & (Y[i]>=20):\n","            Y[i] = 1\n","        elif  (Y[i]<20) & (Y[i]>=10):\n","          Y[i] = 2\n","        elif  (Y[i]<10) & (Y[i]>=0):\n","            Y[i] = 2\n","      label = ['Familier', 'NotUncanny', 'Uncanny', 'Human']\n","\n","    elif labelcategory == \"labelC\":\n","      # 1←好感度は高め(HL20~40)\n","      # 2←好感度は高め(HL40~60)\n","      # 3←不気味ではない(HL0~20)\n","      # 4←不気味ではない(HL60~90)\n","      # 5←HL90~100(不気味)\n","      # 6←HL100（人）\n","      Y = Y.astype(np.float16)\n","      for i in range(len(Y)):\n","        if Y[i] == 100:\n","          Y[i] = 6\n","        elif  (Y[i]<100) & (Y[i]>=90):\n","          Y[i] = 5\n","        elif  (Y[i]<90) & (Y[i]>=80):\n","            Y[i] = 4\n","        elif  (Y[i]<80) & (Y[i]>=70):\n","          Y[i] = 4\n","        elif  (Y[i]<70) & (Y[i]>=60):\n","            Y[i] = 4\n","        elif  (Y[i]<60) & (Y[i]>=50):\n","          Y[i] = 2\n","        elif  (Y[i]<50) & (Y[i]>=40):\n","            Y[i] = 2\n","        elif  (Y[i]<40) & (Y[i]>=30):\n","          Y[i] = 1\n","        elif  (Y[i]<30) & (Y[i]>=20):\n","            Y[i] = 1\n","        elif  (Y[i]<20) & (Y[i]>=10):\n","          Y[i] = 3\n","        elif  (Y[i]<10) & (Y[i]>=0):\n","            Y[i] = 3\n","      label = ['Familier(HL20~40)', 'Familier(HL40~60)', 'NotUncanny(HL0~20)', 'NotUncanny(HL60~90)', 'Uncanny', 'Human']\n","\n","    elif labelcategory == \"labelD\":\n","      # 1←それ以外\n","      # 2←HL70~100(不気味)\n","      # 3←HL100（人）\n","      Y = Y.astype(np.float16)\n","      for i in range(len(Y)):\n","        if Y[i] == 100:\n","          Y[i] = 3\n","        elif  (Y[i]<100) & (Y[i]>=90):\n","          Y[i] = 2\n","        elif  (Y[i]<90) & (Y[i]>=80):\n","            Y[i] = 2\n","        elif  (Y[i]<80) & (Y[i]>=70):\n","          Y[i] = 2\n","        elif  (Y[i]<70) & (Y[i]>=60):\n","            Y[i] = 1\n","        elif  (Y[i]<60) & (Y[i]>=50):\n","          Y[i] = 1\n","        elif  (Y[i]<50) & (Y[i]>=40):\n","            Y[i] = 1\n","        elif  (Y[i]<40) & (Y[i]>=30):\n","          Y[i] = 1\n","        elif  (Y[i]<30) & (Y[i]>=20):\n","            Y[i] = 1\n","        elif  (Y[i]<20) & (Y[i]>=10):\n","          Y[i] = 1\n","        elif  (Y[i]<10) & (Y[i]>=0):\n","            Y[i] = 1\n","      label = ['NotUncanny(HL0~70)', 'Uncanny(HL70~100)', 'Human']\n","      return Y, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QW0ONXuhqfeO"},"outputs":[],"source":["def load_dataset_group(dataset, labelcategory, prefix=''):\n","    filepath = prefix+dataset+\"/\"\n","    filenames = files\n","    X, y = load_group(filenames, dataset, filepath)\n","    labeled_y, label = load_label(labelcategory, y)\n","    return X, labeled_y, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9shfX5Cqj2X"},"outputs":[],"source":["# load the dataset, returns train and test X and y elements\n","def load_dataset(dataset, label):\n","    # load all data\n","    X, y, _ = load_dataset_group(dataset, label, prefix='path')\n","    print(X.shape, y.shape)\n","    _, _, labels = load_dataset_group(dataset, label, prefix='path')\n","    # zero-offset class values\n","    y = y - 1\n","    print(X.shape, y.shape)\n","\n","    return X, y, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BI269BVn36GO"},"outputs":[],"source":["# over sampling\n","def oversampling(X, y):\n","\n","  X = X.reshape(X.shape[0], X.shape[1]*X.shape[2])\n","  print(X.shape, y.shape)\n","\n","  smote = SMOTE(random_state=100)\n","  X_smote, y_smote = smote.fit_resample(X, y)\n","  print(X_smote.shape, y_smote.shape)\n","  X_smote = X_smote.reshape(X_smote.shape[0], 500, 6)\n","\n","  print(X_smote.shape, y_smote.shape)\n","\n","  return X_smote, y_smote"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-OFrqEpGtzUd"},"outputs":[],"source":["# get dataset\n","def get_data(X, y, train_index, test_index):\n","  '''\n","  データを訓練，テスト，検証に分ける\n","  '''\n","  X_train, y_train = X[train_index], y[train_index]\n","  X_test, y_test = X[test_index], y[test_index]\n","\n","  X_train, y_train = oversampling(X_train, y_train)\n","\n","  # データ数のカウント\n","  counter = Counter(y_train)\n","  for k,v in counter.items():\n","    per = v / len(y_train) * 100\n","    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n","\n","  X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=0, shuffle=True, stratify=y_train)#データを訓練データとテストデータに分割\n","\n","  y_tr = to_categorical(y_tr) # one-hotエンコード [0,1,2] ==> [ [1,0,0],[0,1,0],[0,0,1]]\n","  y_val = to_categorical(y_val)\n","\n","  return X_tr, X_val, y_tr, y_val, X_test, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wgeCGN6smCM"},"outputs":[],"source":["def plot_history(history, date, i, path):\n","    # Plot Accuracy History\n","    plt.plot(history.history['accuracy'],\"o-\",label=\"accuracy\")\n","    # plt.plot(history.history['val_accuracy'],\"o-\",label=\"val_acc\")\n","    plt.title('model accuracy')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.legend(loc=\"lower right\")\n","    plt.savefig(f\"{path}accuracy_{date}_{i}.png\")\n","    plt.show()\n","\n","\n","    # Plot Loss History\n","    plt.plot(history.history['loss'],\"o-\",label=\"loss\",)\n","    # plt.plot(history.history['val_loss'],\"o-\",label=\"val_loss\")\n","    plt.title('model loss')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(loc='lower right')\n","    plt.savefig(f\"{path}loss_{date}_{i}.png\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0EGY7orso_N"},"outputs":[],"source":["# fit a model\n","def train_model(label, X_train, y_train, X_val, y_val, date, i, path):\n","    verbose, epochs, batch_size = 0, 15, 32\n","    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n","    model = Sequential()\n","    model.add(LSTM(100, activation='relu', 100, input_shape=(n_timesteps, n_features)))\n","    model.add(Dropout(0.5))\n","    model.add(Flatten())\n","    model.add(Dense(1000, activation='relu'))\n","    model.add(Dense(n_outputs, activation='softmax'))\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.summary()\n","\n","    with open(f\"{path}{date}_summary.txt\", \"w\") as fp:\n","      model.summary(print_fn=lambda x: fp.write(x + \"\\r\\n\"))\n","\n","    # fit network\n","    y_val = to_categorical(y_val)\n","    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","\n","    # plot_history\n","    plot_history(history, date, i, path)\n","    model.save(f\"{path}{date}_model\")\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3XuIvNqsq59"},"outputs":[],"source":["# evaluate a model\n","def evaluate_model(X_test, y_test, score_dict, y_dict, model):\n","\n","  #訓練済みモデルにテストデータを入力して分類する\n","  y_pred = model.predict(X_test)\n","  y_pred = y_pred.argmax(axis=1)\n","  y_test = y_test.ravel()\n","\n","  print(f\"y_pred: {y_pred}, {y_pred.shape}\")\n","  print(f\"y_test: {y_test}, {y_test.shape}\")\n","\n","  y_dict['y_true'].append(y_test.tolist())\n","  y_dict['y_pred'].append(y_pred.tolist())\n","\n","  #モデルの評価をする\n","  score_dict['accuracy'].append(accuracy_score(y_test, y_pred))\n","  score_dict['macro_f1'].append(f1_score(y_test, y_pred, average='macro'))\n","  return y_dict, score_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UfrCw39Cqj7p"},"outputs":[],"source":["def result(score_dict, y_dict, label, date, path):\n","  '''\n","  結果の表示\n","  '''\n","  print('結果')\n","  for i in range(n_splits):\n","    print(i,'回目:')\n","    for metrics, score in score_dict.items():\n","      print(metrics, ' : ', score[i])\n","    print('')\n","\n","  print('全体結果')\n","  y, y_pred=np.array(sum(y_dict['y_true'], [])), np.array(sum(y_dict['y_pred'], []))\n","\n","  for metrics in score_dict.keys():\n","    print(metrics, ';' , np.mean(list(score_dict[metrics])))\n","\n","  with open(f'{path}{date}_results.pkl', 'wb') as f:\n","\t  pickle.dump(score_dict, f)\n","\n","  cm = confusion_matrix(y, y_pred)\n","  plt.figure(figsize=(16, 16))\n","  pcm = ConfusionMatrixDisplay(cm, display_labels=label)\n","  pcm.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n","  pcm.figure_.savefig(f\"{path}{date}_cm\")\n","\n","  return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWBpc5j5pxhP"},"outputs":[],"source":["# run an experiment\n","def main():\n","  score_dict ={'accuracy':[], 'macro_f1':[]}\n","  y_dict = {'y_true':[], 'y_pred':[]}\n","  date = \"20231116_1_smote\"\n","  path = f\"path/{date}/\"\n","  i = 1\n","  # strategy = {0:20, 1:20, 2:20}\n","\n","  #1 データの取得\n","  X, y, label = load_dataset('ML_dataset_20_ICA_baseline_6', 'labelD')\n","  # データ数のカウント\n","  counter = Counter(y[:,0])\n","  for k,v in counter.items():\n","    per = v / len(y) * 100\n","    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n","\n","  kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n","  for train_index, test_index in kf.split(X,y):\n","    #2 データの処理(k-hold　cross validationの実施)\n","    X_tr, X_val, y_tr, y_val, X_test, y_test = get_data(X, y, train_index, test_index)\n","    #3 モデルのトレーニング\n","    model = train_model(label, X_tr, y_tr, X_val, y_val, date, i, path)\n","    #4 モデルの評価\n","    y_dict, score_dict=evaluate_model(X_test, y_test, score_dict, y_dict, model)\n","    i = i + 1\n","\n","  result(score_dict, y_dict, label, date, path)\n","\n","  K.clear_session()\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-Tf7e17lEzA"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOpbf4rDmhyBkqRSO7BSe/U","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
